{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fabeb8b-1025-406a-a7d4-96d183b0bbf0",
   "metadata": {},
   "source": [
    "# Relevant Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39022a4-62f8-4db4-9622-7ddc28febd6d",
   "metadata": {},
   "source": [
    "# Calculate the Realized Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2519849d-2725-4e3d-aaef-335428384635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN with realized return saved: train/sp500_features_with_ret.parquet | rows: 2797\n",
      "        Date  Daily_Return\n",
      "0 2007-08-07      0.476339\n",
      "1 2007-08-10     -1.208174\n",
      "2 2007-08-13     -0.102920\n",
      "3 2007-08-14     -1.393884\n",
      "4 2007-08-15     -1.083829\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "ROOT   = Path(\"./\")  # /ood_validation/macro_retrieval\n",
    "TRAIND = ROOT / \"train\"\n",
    "\n",
    "inp = TRAIND / \"sp500_features.parquet\"\n",
    "out = TRAIND / \"sp500_features_with_ret.parquet\"\n",
    "\n",
    "df = pd.read_parquet(inp).sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Preferred: compute same-day log return from Close/Open\n",
    "if \"Close\" in df.columns:\n",
    "    df[\"Daily_Return\"] = np.log(df[\"Close\"] / df[\"Open\"]).replace([np.inf, -np.inf], np.nan)\n",
    "else:\n",
    "    # Fallback: shift lagged returns forward\n",
    "    if \"Daily_Return_lag1\" not in df.columns:\n",
    "        raise KeyError(\"Neither Close nor Daily_Return_lag1 found in train data.\")\n",
    "    df[\"Daily_Return\"] = df[\"Daily_Return_lag1\"].shift(-1)\n",
    "\n",
    "# Drop trailing NaNs (from shift edge)\n",
    "nan_tail = int(df[\"Daily_Return\"].isna().sum())\n",
    "if nan_tail:\n",
    "    df = df.iloc[:-nan_tail].copy()\n",
    "\n",
    "df.to_parquet(out, index=False)\n",
    "print(\"TRAIN with realized return saved:\", out, \"| rows:\", len(df))\n",
    "print(df[[\"Date\",\"Daily_Return\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cb5c320c-e131-4cd6-b849-36adedb0be15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOD with realized return saved: test/x_test_ood_base_with_ret.parquet | rows: 227\n",
      "        Date  Daily_Return\n",
      "0 2024-01-09     -0.196457\n",
      "1 2024-01-10      0.844844\n",
      "2 2024-01-11      0.313409\n",
      "3 2024-01-12     -2.372397\n",
      "4 2024-01-16     -1.184751\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "ROOT  = Path(\"./\")  # /ood_validation/macro_retrieval\n",
    "TESTD = ROOT / \"test\"\n",
    "\n",
    "# Use whichever file you’ll evaluate (base or with retrieval)\n",
    "inp = TESTD / \"x_test_ood.parquet\"\n",
    "if not inp.exists():\n",
    "    inp = TESTD / \"x_test_ood_base.parquet\"\n",
    "\n",
    "out = inp.with_name(inp.stem + \"_with_ret.parquet\")\n",
    "\n",
    "df = pd.read_parquet(inp).sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "if \"Close\" in df.columns:\n",
    "    df[\"Daily_Return\"] = np.log(df[\"Close\"] / df[\"Open\"]).replace([np.inf, -np.inf], np.nan)\n",
    "else:\n",
    "    if \"Daily_Return_lag1\" not in df.columns:\n",
    "        raise KeyError(\"Neither Close nor Daily_Return_lag1 found in OOD data.\")\n",
    "    df[\"Daily_Return\"] = df[\"Daily_Return_lag1\"].shift(-1)\n",
    "\n",
    "nan_tail = int(df[\"Daily_Return\"].isna().sum())\n",
    "if nan_tail:\n",
    "    df = df.iloc[:-nan_tail].copy()\n",
    "\n",
    "df.to_parquet(out, index=False)\n",
    "print(\"OOD with realized return saved:\", out, \"| rows:\", len(df))\n",
    "print(df[[\"Date\",\"Daily_Return\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54af7a0-7dda-4ba5-ab2e-d6a24cc046b0",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c73dc5-c987-4bb8-a229-3ccabc7a7470",
   "metadata": {},
   "source": [
    "# Numeircal Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ff00b0d-9c90-4bac-874c-fe17e64da77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TRAIN: train/sp500_features_with_ret.parquet\n",
      "Using OOD  : test/x_test_ood_base_with_ret.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT   = Path(\"./\")  # notebook at /ood_validation/macro_retrieval\n",
    "TRAIND = ROOT / \"train\"\n",
    "TESTD  = ROOT / \"test\"\n",
    "\n",
    "# Prefer files with realized-return; fallback to originals\n",
    "def pick_train_path():\n",
    "    p1 = TRAIND / \"sp500_features_with_ret.parquet\"\n",
    "    p0 = TRAIND / \"sp500_features.parquet\"\n",
    "    return p1 if p1.exists() else p0\n",
    "\n",
    "def pick_ood_path():\n",
    "    # prefer OOD with retrieval; else base; both prefer *_with_ret if available\n",
    "    cands = [\n",
    "        TESTD / \"x_test_ood_with_ret.parquet\",\n",
    "        TESTD / \"x_test_ood.parquet\",\n",
    "        TESTD / \"x_test_ood_base_with_ret.parquet\",\n",
    "        TESTD / \"x_test_ood_base.parquet\",\n",
    "    ]\n",
    "    for p in cands:\n",
    "        if p.exists(): return p\n",
    "    raise FileNotFoundError(\"No OOD parquet found in /test.\")\n",
    "\n",
    "TRAIN_PARQUET = pick_train_path()\n",
    "OOD_PARQUET   = pick_ood_path()\n",
    "\n",
    "print(\"Using TRAIN:\", TRAIN_PARQUET)\n",
    "print(\"Using OOD  :\", OOD_PARQUET)\n",
    "\n",
    "train = pd.read_parquet(TRAIN_PARQUET).sort_values(\"Date\").reset_index(drop=True)\n",
    "ood   = pd.read_parquet(OOD_PARQUET).sort_values(\"Date\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "863cfca8-1d50-432f-9783-b029d3241a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trading_metrics(y_true, y_pred, realized_ret):\n",
    "    if realized_ret is None or len(realized_ret) == 0:\n",
    "        return {\"win_rate\": None, \"profit_factor\": None, \"sharpe_252\": None}\n",
    "    pos = np.where(np.asarray(y_pred) > 0, 1.0, -1.0)\n",
    "    strat_ret = pos * np.asarray(realized_ret)\n",
    "    win_rate = (strat_ret > 0).mean()\n",
    "    gross_profit = strat_ret[strat_ret > 0].sum()\n",
    "    gross_loss   = -strat_ret[strat_ret < 0].sum()\n",
    "    profit_factor = (gross_profit / gross_loss) if gross_loss > 0 else np.inf\n",
    "    mu, sd = strat_ret.mean(), strat_ret.std(ddof=1)\n",
    "    sharpe_252 = (mu / sd) * np.sqrt(252) if sd > 0 else np.nan\n",
    "    return {\"win_rate\": float(win_rate), \"profit_factor\": float(profit_factor), \"sharpe_252\": float(sharpe_252)}\n",
    "\n",
    "def realized_return_column(df):\n",
    "    # Prefer explicitly-added realized return\n",
    "    if \"Daily_Return\" in df.columns and pd.api.types.is_numeric_dtype(df[\"Daily_Return\"]):\n",
    "        return \"Daily_Return\"\n",
    "    # Fallbacks (rare)\n",
    "    for c in [\"ret\", \"RET\", \"strategy_return\", \"realized_return\"]:\n",
    "        if c in df.columns and pd.api.types.is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c17e33b9-7861-496f-af49-684ad7a81f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric-only features: 8\n"
     ]
    }
   ],
   "source": [
    "def pick_numeric_only_columns(df):\n",
    "    drop_exact = {\n",
    "        \"Date\",\"Movement\",\"text_embed\",\"z_retr\",\n",
    "        \"cpi_yoy_lagged_z\",\"unrate_lagged_z\",\"t10y2y_lagged_z\",\"gdp_qoq_lagged_z\",\n",
    "        \"Daily_Return\"  # never use realized return as a feature\n",
    "    }\n",
    "    keep = [c for c in df.columns if c not in drop_exact and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    return keep\n",
    "\n",
    "X_cols = pick_numeric_only_columns(train)\n",
    "print(\"Numeric-only features:\", len(X_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19f3e29f-ad77-44a7-8415-20a161a331be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric-only features: 8\n",
      "Train rows: 2797 Train date range: 2007-08-07 → 2023-07-12\n",
      "\n",
      "=== CV results (per fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>n_val</th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>WinRate</th>\n",
       "      <th>ProfitFactor</th>\n",
       "      <th>Sharpe_252</th>\n",
       "      <th>ret_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>466</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>0.680258</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.624685</td>\n",
       "      <td>0.451097</td>\n",
       "      <td>0.845836</td>\n",
       "      <td>0.620172</td>\n",
       "      <td>2.561426</td>\n",
       "      <td>5.287349</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>0.579399</td>\n",
       "      <td>0.574932</td>\n",
       "      <td>0.840637</td>\n",
       "      <td>0.682848</td>\n",
       "      <td>0.140222</td>\n",
       "      <td>0.647234</td>\n",
       "      <td>0.512876</td>\n",
       "      <td>1.144653</td>\n",
       "      <td>0.728899</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>0.639485</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.283174</td>\n",
       "      <td>0.872649</td>\n",
       "      <td>0.508584</td>\n",
       "      <td>1.103695</td>\n",
       "      <td>0.538566</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>0.684549</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794979</td>\n",
       "      <td>0.352031</td>\n",
       "      <td>0.866996</td>\n",
       "      <td>0.600858</td>\n",
       "      <td>2.541406</td>\n",
       "      <td>4.179627</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>466</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>0.510730</td>\n",
       "      <td>0.502183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.668605</td>\n",
       "      <td>0.130473</td>\n",
       "      <td>0.882867</td>\n",
       "      <td>0.461373</td>\n",
       "      <td>0.938593</td>\n",
       "      <td>-0.383703</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  n_val   val_start     val_end  Accuracy  Precision    Recall        F1       MCC     AUROC   WinRate  ProfitFactor  Sharpe_252       ret_col\n",
       "0     1    466  2012-09-07  2015-12-03  0.680258   0.905109  0.476923  0.624685  0.451097  0.845836  0.620172      2.561426    5.287349  Daily_Return\n",
       "1     2    466  2015-12-04  2017-10-17  0.579399   0.574932  0.840637  0.682848  0.140222  0.647234  0.512876      1.144653    0.728899  Daily_Return\n",
       "2     3    466  2017-10-18  2019-10-03  0.639485   0.619048  1.000000  0.764706  0.283174  0.872649  0.508584      1.103695    0.538566  Daily_Return\n",
       "3     4    466  2019-10-04  2021-08-26  0.684549   0.659722  1.000000  0.794979  0.352031  0.866996  0.600858      2.541406    4.179627  Daily_Return\n",
       "4     5    466  2021-08-27  2023-07-12  0.510730   0.502183  1.000000  0.668605  0.130473  0.882867  0.461373      0.938593   -0.383703  Daily_Return"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV means ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy        0.618884\n",
       "Precision       0.652199\n",
       "Recall          0.863512\n",
       "F1              0.707165\n",
       "MCC             0.271399\n",
       "AUROC           0.823117\n",
       "WinRate         0.540773\n",
       "ProfitFactor    1.657955\n",
       "Sharpe_252      2.070147\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef, roc_auc_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Features/labels\n",
    "X_cols = pick_numeric_only_columns(train)\n",
    "y_col  = \"Movement\"\n",
    "\n",
    "print(\"Numeric-only features:\", len(X_cols))\n",
    "print(\"Train rows:\", len(train), \"Train date range:\",\n",
    "      train[\"Date\"].min().date(), \"→\", train[\"Date\"].max().date())\n",
    "\n",
    "# CV setup\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_rows = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), 1):\n",
    "    tr_df = train.iloc[tr_idx].copy()\n",
    "    va_df = train.iloc[va_idx].copy()\n",
    "\n",
    "    X_tr, y_tr = tr_df[X_cols].to_numpy(), tr_df[y_col].to_numpy()\n",
    "    X_va, y_va = va_df[X_cols].to_numpy(), va_df[y_col].to_numpy()\n",
    "\n",
    "    # Pipeline: scale numerics → LR\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", LogisticRegression(max_iter=500, solver=\"liblinear\", n_jobs=1, random_state=42))\n",
    "    ])\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    proba_va = pipe.predict_proba(X_va)[:, 1]\n",
    "    yhat_va  = (proba_va >= 0.5).astype(int)\n",
    "\n",
    "    # Classification metrics\n",
    "    acc  = accuracy_score(y_va, yhat_va)\n",
    "    prec = precision_score(y_va, yhat_va, zero_division=0)\n",
    "    rec  = recall_score(y_va, yhat_va, zero_division=0)\n",
    "    f1   = f1_score(y_va, yhat_va, zero_division=0)\n",
    "    mcc  = matthews_corrcoef(y_va, yhat_va)\n",
    "    try:\n",
    "        auroc = roc_auc_score(y_va, proba_va)\n",
    "    except ValueError:\n",
    "        auroc = np.nan\n",
    "\n",
    "    # Trading metrics (if realized return exists)\n",
    "    rr_col = realized_return_column(va_df)\n",
    "    tm = trading_metrics(y_va, yhat_va, va_df[rr_col].to_numpy() if rr_col else None)\n",
    "\n",
    "    cv_rows.append({\n",
    "        \"fold\": fold, \"n_val\": len(va_df),\n",
    "        \"val_start\": va_df[\"Date\"].min().date(),\n",
    "        \"val_end\": va_df[\"Date\"].max().date(),\n",
    "        \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"MCC\": mcc, \"AUROC\": auroc,\n",
    "        \"WinRate\": tm[\"win_rate\"], \"ProfitFactor\": tm[\"profit_factor\"], \"Sharpe_252\": tm[\"sharpe_252\"],\n",
    "        \"ret_col\": rr_col\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_rows)\n",
    "print(\"\\n=== CV results (per fold) ===\")\n",
    "display(cv_df)\n",
    "\n",
    "print(\"\\n=== CV means ===\")\n",
    "display(cv_df[[\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"MCC\",\"AUROC\",\"WinRate\",\"ProfitFactor\",\"Sharpe_252\"]]\n",
    "        .mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6e5b3ef0-82ce-4279-b4fd-813eb3799c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOD rows: 227 OOD date range: 2024-01-09 → 2024-12-09\n",
      "\n",
      "=== OOD (AAPL 2024) — Numerical-only LR ===\n",
      "Accuracy: 0.4758 | Precision: 0.4507 | Recall: 0.9796 | F1: 0.6174 | MCC: 0.1495 | AUROC: 0.5715\n",
      "WinRate: 0.4097 | ProfitFactor: 0.7584 | Sharpe_252: -1.5792 | ReturnCol: Daily_Return\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef, roc_auc_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Train full model on TRAIN\n",
    "pipe_full = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"liblinear\", n_jobs=1, random_state=42))\n",
    "])\n",
    "pipe_full.fit(train[X_cols].to_numpy(), train[\"Movement\"].to_numpy())\n",
    "\n",
    "# Predict on OOD\n",
    "print(\"OOD rows:\", len(ood), \"OOD date range:\", ood[\"Date\"].min().date(), \"→\", ood[\"Date\"].max().date())\n",
    "X_test = ood[X_cols].to_numpy()\n",
    "y_test = ood[\"Movement\"].to_numpy()\n",
    "\n",
    "proba_test = pipe_full.predict_proba(X_test)[:, 1]\n",
    "yhat_test  = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "# Classification metrics\n",
    "acc  = accuracy_score(y_test, yhat_test)\n",
    "prec = precision_score(y_test, yhat_test, zero_division=0)\n",
    "rec  = recall_score(y_test, yhat_test, zero_division=0)\n",
    "f1   = f1_score(y_test, yhat_test, zero_division=0)\n",
    "mcc  = matthews_corrcoef(y_test, yhat_test)\n",
    "try:\n",
    "    auroc = roc_auc_score(y_test, proba_test)\n",
    "except ValueError:\n",
    "    auroc = np.nan\n",
    "\n",
    "# Trading metrics on OOD\n",
    "rr_col_test = realized_return_column(ood)\n",
    "tm = trading_metrics(y_test, yhat_test, ood[rr_col_test].to_numpy() if rr_col_test else None)\n",
    "\n",
    "print(\"\\n=== OOD (AAPL 2024) — Numerical-only LR ===\")\n",
    "print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | MCC: {mcc:.4f} | AUROC: {auroc:.4f}\")\n",
    "if rr_col_test:\n",
    "    print(f\"WinRate: {tm['win_rate']:.4f} | ProfitFactor: {tm['profit_factor']:.4f} | Sharpe_252: {tm['sharpe_252']:.4f} | ReturnCol: {rr_col_test}\")\n",
    "else:\n",
    "    print(\"No realized-return column found in OOD; trading metrics skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d24a53-9d53-460d-bd5b-8c7e3769416d",
   "metadata": {},
   "source": [
    "# Text Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "02660068-f473-43c9-a79f-9f6b97e0f90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using text-only features from column: text_embed\n"
     ]
    }
   ],
   "source": [
    "def pick_text_only_columns(df):\n",
    "    # text_embed is stored as list/array → expand into numpy\n",
    "    if \"text_embed\" not in df.columns:\n",
    "        raise KeyError(\"text_embed column not found in dataframe\")\n",
    "    return \"text_embed\"\n",
    "\n",
    "X_col_text = pick_text_only_columns(train)\n",
    "print(\"Using text-only features from column:\", X_col_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2fcd8380-23dd-4414-ac9e-ecbc1881c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Text-only CV results (per fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>n_val</th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>WinRate</th>\n",
       "      <th>ProfitFactor</th>\n",
       "      <th>Sharpe_252</th>\n",
       "      <th>ret_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>466</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>0.521459</td>\n",
       "      <td>0.604520</td>\n",
       "      <td>0.411538</td>\n",
       "      <td>0.489703</td>\n",
       "      <td>0.073401</td>\n",
       "      <td>0.518913</td>\n",
       "      <td>0.512876</td>\n",
       "      <td>1.177658</td>\n",
       "      <td>0.934971</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>0.540773</td>\n",
       "      <td>0.539957</td>\n",
       "      <td>0.996016</td>\n",
       "      <td>0.700280</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.509182</td>\n",
       "      <td>0.444206</td>\n",
       "      <td>0.848440</td>\n",
       "      <td>-0.886536</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>0.583691</td>\n",
       "      <td>0.588764</td>\n",
       "      <td>0.959707</td>\n",
       "      <td>0.729805</td>\n",
       "      <td>0.027355</td>\n",
       "      <td>0.470649</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>0.864955</td>\n",
       "      <td>-0.791702</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>0.603004</td>\n",
       "      <td>0.608225</td>\n",
       "      <td>0.985965</td>\n",
       "      <td>0.752343</td>\n",
       "      <td>-0.074153</td>\n",
       "      <td>0.523834</td>\n",
       "      <td>0.540773</td>\n",
       "      <td>1.025120</td>\n",
       "      <td>0.115186</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>466</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491728</td>\n",
       "      <td>0.452790</td>\n",
       "      <td>0.842458</td>\n",
       "      <td>-1.037679</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  n_val   val_start     val_end  Accuracy  Precision    Recall        F1       MCC     AUROC   WinRate  ProfitFactor  Sharpe_252       ret_col\n",
       "0     1    466  2012-09-07  2015-12-03  0.521459   0.604520  0.411538  0.489703  0.073401  0.518913  0.512876      1.177658    0.934971  Daily_Return\n",
       "1     2    466  2015-12-04  2017-10-17  0.540773   0.539957  0.996016  0.700280  0.033149  0.509182  0.444206      0.848440   -0.886536  Daily_Return\n",
       "2     3    466  2017-10-18  2019-10-03  0.583691   0.588764  0.959707  0.729805  0.027355  0.470649  0.478541      0.864955   -0.791702  Daily_Return\n",
       "3     4    466  2019-10-04  2021-08-26  0.603004   0.608225  0.985965  0.752343 -0.074153  0.523834  0.540773      1.025120    0.115186  Daily_Return\n",
       "4     5    466  2021-08-27  2023-07-12  0.493562   0.493562  1.000000  0.660920  0.000000  0.491728  0.452790      0.842458   -1.037679  Daily_Return"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Text-only CV means ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy        0.548498\n",
       "Precision       0.567006\n",
       "Recall          0.870645\n",
       "F1              0.666610\n",
       "MCC             0.011951\n",
       "AUROC           0.502861\n",
       "WinRate         0.485837\n",
       "ProfitFactor    0.951726\n",
       "Sharpe_252     -0.333152\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef, roc_auc_score\n",
    ")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_rows = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), 1):\n",
    "    tr_df, va_df = train.iloc[tr_idx], train.iloc[va_idx]\n",
    "\n",
    "    # Expand embeddings to numpy\n",
    "    X_tr = np.vstack(tr_df[X_col_text].to_numpy())\n",
    "    X_va = np.vstack(va_df[X_col_text].to_numpy())\n",
    "    y_tr, y_va = tr_df[\"Movement\"].to_numpy(), va_df[\"Movement\"].to_numpy()\n",
    "\n",
    "    # Logistic Regression (no scaling needed for embeddings)\n",
    "    clf = LogisticRegression(max_iter=500, solver=\"liblinear\", n_jobs=1, random_state=42)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    proba_va = clf.predict_proba(X_va)[:, 1]\n",
    "    yhat_va  = (proba_va >= 0.5).astype(int)\n",
    "\n",
    "    # Classification metrics\n",
    "    acc  = accuracy_score(y_va, yhat_va)\n",
    "    prec = precision_score(y_va, yhat_va, zero_division=0)\n",
    "    rec  = recall_score(y_va, yhat_va, zero_division=0)\n",
    "    f1   = f1_score(y_va, yhat_va, zero_division=0)\n",
    "    mcc  = matthews_corrcoef(y_va, yhat_va)\n",
    "    try:\n",
    "        auroc = roc_auc_score(y_va, proba_va)\n",
    "    except ValueError:\n",
    "        auroc = np.nan\n",
    "\n",
    "    # Trading metrics\n",
    "    rr_col = realized_return_column(va_df)\n",
    "    tm = trading_metrics(y_va, yhat_va, va_df[rr_col].to_numpy() if rr_col else None)\n",
    "\n",
    "    cv_rows.append({\n",
    "        \"fold\": fold, \"n_val\": len(va_df),\n",
    "        \"val_start\": va_df[\"Date\"].min().date(), \"val_end\": va_df[\"Date\"].max().date(),\n",
    "        \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"MCC\": mcc, \"AUROC\": auroc,\n",
    "        \"WinRate\": tm[\"win_rate\"], \"ProfitFactor\": tm[\"profit_factor\"], \"Sharpe_252\": tm[\"sharpe_252\"],\n",
    "        \"ret_col\": rr_col\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_rows)\n",
    "print(\"\\n=== Text-only CV results (per fold) ===\")\n",
    "display(cv_df)\n",
    "\n",
    "print(\"\\n=== Text-only CV means ===\")\n",
    "display(cv_df[[\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"MCC\",\"AUROC\",\"WinRate\",\"ProfitFactor\",\"Sharpe_252\"]]\n",
    "        .mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a729b0ac-7608-4647-975f-995c81d98212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOD (AAPL 2024) — Text-only LR ===\n",
      "Rows: 227 Date range: 2024-01-09 → 2024-12-09\n",
      "Accuracy: 0.4317 | Precision: 0.4317 | Recall: 1.0000 | F1: 0.6031 | MCC: 0.0000 | AUROC: 0.4205\n",
      "WinRate: 0.4009 | ProfitFactor: 0.6686 | Sharpe_252: -2.2949 | ReturnCol: Daily_Return\n"
     ]
    }
   ],
   "source": [
    "# Full-train model\n",
    "X_tr_full = np.vstack(train[X_col_text].to_numpy())\n",
    "y_tr_full = train[\"Movement\"].to_numpy()\n",
    "\n",
    "clf_full = LogisticRegression(max_iter=1000, solver=\"liblinear\", n_jobs=1, random_state=42)\n",
    "clf_full.fit(X_tr_full, y_tr_full)\n",
    "\n",
    "# OOD evaluation\n",
    "X_test = np.vstack(ood[X_col_text].to_numpy())\n",
    "y_test = ood[\"Movement\"].to_numpy()\n",
    "\n",
    "proba_test = clf_full.predict_proba(X_test)[:, 1]\n",
    "yhat_test  = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "acc  = accuracy_score(y_test, yhat_test)\n",
    "prec = precision_score(y_test, yhat_test, zero_division=0)\n",
    "rec  = recall_score(y_test, yhat_test, zero_division=0)\n",
    "f1   = f1_score(y_test, yhat_test, zero_division=0)\n",
    "mcc  = matthews_corrcoef(y_test, yhat_test)\n",
    "try:\n",
    "    auroc = roc_auc_score(y_test, proba_test)\n",
    "except ValueError:\n",
    "    auroc = np.nan\n",
    "\n",
    "rr_col_test = realized_return_column(ood)\n",
    "tm = trading_metrics(y_test, yhat_test, ood[rr_col_test].to_numpy() if rr_col_test else None)\n",
    "\n",
    "print(\"\\n=== OOD (AAPL 2024) — Text-only LR ===\")\n",
    "print(\"Rows:\", len(ood), \"Date range:\", ood[\"Date\"].min().date(), \"→\", ood[\"Date\"].max().date())\n",
    "print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | MCC: {mcc:.4f} | AUROC: {auroc:.4f}\")\n",
    "if rr_col_test:\n",
    "    print(f\"WinRate: {tm['win_rate']:.4f} | ProfitFactor: {tm['profit_factor']:.4f} | Sharpe_252: {tm['sharpe_252']:.4f} | ReturnCol: {rr_col_test}\")\n",
    "else:\n",
    "    print(\"No realized-return column found in OOD; trading metrics skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02153d63-c95c-4505-9f80-15fc0279a255",
   "metadata": {},
   "source": [
    "# 3. Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd984884-b602-49b7-b615-049ac76a37a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal numeric+macro feature count: 12\n",
      "First 10 numeric/macro cols: ['Open', 'Close_lag1', 'High_lag1', 'Volume_lag1', 'Daily_Return_lag1', 'Volatility_lag1', 'sentiment_volatility_lag1', 'aggregate_sentiment_score_lag1', 'cpi_yoy_lagged_z', 'unrate_lagged_z']\n",
      "Using text column: text_embed\n"
     ]
    }
   ],
   "source": [
    "# Numeric (incl. macro_z) + text_embed, exclude labels/leakage columns\n",
    "def pick_numeric_incl_macro(df):\n",
    "    drop = {\n",
    "        \"Date\",\"Movement\",\"z_retr\",\"Daily_Return\",  # label/leakage\n",
    "        # keep macro_z this time (unlike the numeric-only baseline)\n",
    "    }\n",
    "    keep = []\n",
    "    for c in df.columns:\n",
    "        if c in drop: \n",
    "            continue\n",
    "        if c == \"text_embed\":\n",
    "            continue  # handled separately\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            keep.append(c)\n",
    "    return keep\n",
    "\n",
    "num_cols_mm = pick_numeric_incl_macro(train)\n",
    "text_col    = \"text_embed\"\n",
    "\n",
    "print(\"Multimodal numeric+macro feature count:\", len(num_cols_mm))\n",
    "print(\"First 10 numeric/macro cols:\", num_cols_mm[:10])\n",
    "print(\"Using text column:\", text_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb6a8c5e-d2f2-466b-8d91-d78a54fdf971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multimodal (No-Ret) CV results (per fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>n_val</th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>WinRate</th>\n",
       "      <th>ProfitFactor</th>\n",
       "      <th>Sharpe_252</th>\n",
       "      <th>ret_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>466</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>0.641631</td>\n",
       "      <td>0.614251</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.749625</td>\n",
       "      <td>0.297802</td>\n",
       "      <td>0.752987</td>\n",
       "      <td>0.577253</td>\n",
       "      <td>1.802142</td>\n",
       "      <td>3.347154</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>0.551502</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.956175</td>\n",
       "      <td>0.696662</td>\n",
       "      <td>0.073933</td>\n",
       "      <td>0.613972</td>\n",
       "      <td>0.459227</td>\n",
       "      <td>0.904769</td>\n",
       "      <td>-0.540038</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>0.667382</td>\n",
       "      <td>0.648241</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.769001</td>\n",
       "      <td>0.306498</td>\n",
       "      <td>0.783294</td>\n",
       "      <td>0.515021</td>\n",
       "      <td>1.282910</td>\n",
       "      <td>1.358183</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>0.665236</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.250679</td>\n",
       "      <td>0.678143</td>\n",
       "      <td>0.564378</td>\n",
       "      <td>1.946086</td>\n",
       "      <td>3.036088</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>466</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>0.624464</td>\n",
       "      <td>0.568922</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.721781</td>\n",
       "      <td>0.367838</td>\n",
       "      <td>0.796794</td>\n",
       "      <td>0.536481</td>\n",
       "      <td>1.491961</td>\n",
       "      <td>2.418346</td>\n",
       "      <td>Daily_Return</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  n_val   val_start     val_end  Accuracy  Precision    Recall        F1       MCC     AUROC   WinRate  ProfitFactor  Sharpe_252       ret_col\n",
       "0     1    466  2012-09-07  2015-12-03  0.641631   0.614251  0.961538  0.749625  0.297802  0.752987  0.577253      1.802142    3.347154  Daily_Return\n",
       "1     2    466  2015-12-04  2017-10-17  0.551502   0.547945  0.956175  0.696662  0.073933  0.613972  0.459227      0.904769   -0.540038  Daily_Return\n",
       "2     3    466  2017-10-18  2019-10-03  0.667382   0.648241  0.945055  0.769001  0.306498  0.783294  0.515021      1.282910    1.358183  Daily_Return\n",
       "3     4    466  2019-10-04  2021-08-26  0.665236   0.661654  0.926316  0.771930  0.250679  0.678143  0.564378      1.946086    3.036088  Daily_Return\n",
       "4     5    466  2021-08-27  2023-07-12  0.624464   0.568922  0.986957  0.721781  0.367838  0.796794  0.536481      1.491961    2.418346  Daily_Return"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multimodal (No-Ret) CV means ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy        0.630043\n",
       "Precision       0.608203\n",
       "Recall          0.955208\n",
       "F1              0.741800\n",
       "MCC             0.259350\n",
       "AUROC           0.725038\n",
       "WinRate         0.530472\n",
       "ProfitFactor    1.485574\n",
       "Sharpe_252      1.923947\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef, roc_auc_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_rows = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), 1):\n",
    "    tr_df, va_df = train.iloc[tr_idx], train.iloc[va_idx]\n",
    "\n",
    "    # Split by modality\n",
    "    Xnum_tr = tr_df[num_cols_mm].to_numpy(dtype=float)\n",
    "    Xnum_va = va_df[num_cols_mm].to_numpy(dtype=float)\n",
    "    Xtxt_tr = np.vstack(tr_df[text_col].to_numpy()).astype(\"float32\")\n",
    "    Xtxt_va = np.vstack(va_df[text_col].to_numpy()).astype(\"float32\")\n",
    "\n",
    "    # Scale numerics (+macro_z) only; leave embeddings as-is\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xnum_tr_s = scaler.fit_transform(Xnum_tr)\n",
    "    Xnum_va_s = scaler.transform(Xnum_va)\n",
    "\n",
    "    # Concatenate: [scaled numerics+macro | text embedding]\n",
    "    X_tr = np.hstack([Xnum_tr_s, Xtxt_tr]).astype(\"float32\")\n",
    "    X_va = np.hstack([Xnum_va_s, Xtxt_va]).astype(\"float32\")\n",
    "    y_tr = tr_df[\"Movement\"].to_numpy()\n",
    "    y_va = va_df[\"Movement\"].to_numpy()\n",
    "\n",
    "    # LR classifier\n",
    "    clf = LogisticRegression(max_iter=1000, solver=\"liblinear\", n_jobs=1, random_state=42)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    proba_va = clf.predict_proba(X_va)[:, 1]\n",
    "    yhat_va  = (proba_va >= 0.5).astype(int)\n",
    "\n",
    "    # Classification metrics\n",
    "    acc  = accuracy_score(y_va, yhat_va)\n",
    "    prec = precision_score(y_va, yhat_va, zero_division=0)\n",
    "    rec  = recall_score(y_va, yhat_va, zero_division=0)\n",
    "    f1   = f1_score(y_va, yhat_va, zero_division=0)\n",
    "    mcc  = matthews_corrcoef(y_va, yhat_va)\n",
    "    try:\n",
    "        auroc = roc_auc_score(y_va, proba_va)\n",
    "    except ValueError:\n",
    "        auroc = np.nan\n",
    "\n",
    "    # Trading metrics\n",
    "    rr_col = realized_return_column(va_df)\n",
    "    tm = trading_metrics(y_va, yhat_va, va_df[rr_col].to_numpy() if rr_col else None)\n",
    "\n",
    "    cv_rows.append({\n",
    "        \"fold\": fold, \"n_val\": len(va_df),\n",
    "        \"val_start\": va_df[\"Date\"].min().date(), \"val_end\": va_df[\"Date\"].max().date(),\n",
    "        \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"MCC\": mcc, \"AUROC\": auroc,\n",
    "        \"WinRate\": tm[\"win_rate\"], \"ProfitFactor\": tm[\"profit_factor\"], \"Sharpe_252\": tm[\"sharpe_252\"],\n",
    "        \"ret_col\": rr_col\n",
    "    })\n",
    "\n",
    "cv_df_mm = pd.DataFrame(cv_rows)\n",
    "print(\"\\n=== Multimodal (No-Ret) CV results (per fold) ===\")\n",
    "display(cv_df_mm)\n",
    "\n",
    "print(\"\\n=== Multimodal (No-Ret) CV means ===\")\n",
    "display(cv_df_mm[[\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"MCC\",\"AUROC\",\"WinRate\",\"ProfitFactor\",\"Sharpe_252\"]]\n",
    "        .mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0bbd8f9b-2186-476b-a7b9-3528b0f0c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OOD (AAPL 2024) — Multimodal (No-Ret) LR ===\n",
      "Rows: 227 Date range: 2024-01-09 → 2024-12-09\n",
      "Accuracy: 0.4714 | Precision: 0.4337 | Recall: 0.7347 | F1: 0.5455 | MCC: 0.0067 | AUROC: 0.4981\n",
      "WinRate: 0.4405 | ProfitFactor: 0.9988 | Sharpe_252: -0.0071 | ReturnCol: Daily_Return\n"
     ]
    }
   ],
   "source": [
    "# Build full-train matrices\n",
    "Xnum_full = train[num_cols_mm].to_numpy(dtype=float)\n",
    "Xtxt_full = np.vstack(train[text_col].to_numpy()).astype(\"float32\")\n",
    "scaler_full = StandardScaler(with_mean=True, with_std=True)\n",
    "Xnum_full_s = scaler_full.fit_transform(Xnum_full)\n",
    "X_full = np.hstack([Xnum_full_s, Xtxt_full]).astype(\"float32\")\n",
    "y_full = train[\"Movement\"].to_numpy()\n",
    "\n",
    "clf_full = LogisticRegression(max_iter=2000, solver=\"liblinear\", n_jobs=1, random_state=42)\n",
    "clf_full.fit(X_full, y_full)\n",
    "\n",
    "# OOD matrices\n",
    "Xnum_test = ood[num_cols_mm].to_numpy(dtype=float)\n",
    "Xtxt_test = np.vstack(ood[text_col].to_numpy()).astype(\"float32\")\n",
    "Xnum_test_s = scaler_full.transform(Xnum_test)\n",
    "X_test = np.hstack([Xnum_test_s, Xtxt_test]).astype(\"float32\")\n",
    "y_test = ood[\"Movement\"].to_numpy()\n",
    "\n",
    "proba_test = clf_full.predict_proba(X_test)[:, 1]\n",
    "yhat_test  = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef, roc_auc_score\n",
    ")\n",
    "acc  = accuracy_score(y_test, yhat_test)\n",
    "prec = precision_score(y_test, yhat_test, zero_division=0)\n",
    "rec  = recall_score(y_test, yhat_test, zero_division=0)\n",
    "f1   = f1_score(y_test, yhat_test, zero_division=0)\n",
    "mcc  = matthews_corrcoef(y_test, yhat_test)\n",
    "try:\n",
    "    auroc = roc_auc_score(y_test, proba_test)\n",
    "except ValueError:\n",
    "    auroc = np.nan\n",
    "\n",
    "rr_col_test = realized_return_column(ood)\n",
    "tm = trading_metrics(y_test, yhat_test, ood[rr_col_test].to_numpy() if rr_col_test else None)\n",
    "\n",
    "print(\"\\n=== OOD (AAPL 2024) — Multimodal (No-Ret) LR ===\")\n",
    "print(\"Rows:\", len(ood), \"Date range:\", ood[\"Date\"].min().date(), \"→\", ood[\"Date\"].max().date())\n",
    "print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | MCC: {mcc:.4f} | AUROC: {auroc:.4f}\")\n",
    "if rr_col_test:\n",
    "    print(f\"WinRate: {tm['win_rate']:.4f} | ProfitFactor: {tm['profit_factor']:.4f} | Sharpe_252: {tm['sharpe_252']:.4f} | ReturnCol: {rr_col_test}\")\n",
    "else:\n",
    "    print(\"No realized-return column found in OOD; trading metrics skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495fd82-1ae0-4e2e-aea5-24e75308c64d",
   "metadata": {},
   "source": [
    "# Retrieval Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a4afc-9113-491c-8bef-a59d2ede191b",
   "metadata": {},
   "source": [
    "# Text Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2abaadbc-9eb4-4580-a343-1b164d776547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: train/sp500_features_with_ret.parquet\n",
      "OOD  : test/x_test_ood_base_with_ret.parquet\n",
      "Numerics (no macro_z) count: 8 | text col: text_embed\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\",\"1\"); os.environ.setdefault(\"MKL_NUM_THREADS\",\"1\")\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, matthews_corrcoef, roc_auc_score)\n",
    "\n",
    "ROOT   = Path(\"./\")            # notebook at /ood_validation/macro_retrieval\n",
    "TRAIND = ROOT / \"train\"\n",
    "TESTD  = ROOT / \"test\"\n",
    "\n",
    "# prefer files with realized returns\n",
    "TRAIN_PARQUET = (TRAIND/\"sp500_features_with_ret.parquet\") if (TRAIND/\"sp500_features_with_ret.parquet\").exists() else (TRAIND/\"sp500_features.parquet\")\n",
    "OOD_PARQUET_CAND = [\n",
    "    TESTD/\"x_test_ood_alpha0_with_ret.parquet\",\n",
    "    TESTD/\"x_test_ood_with_ret.parquet\",\n",
    "    TESTD/\"x_test_ood_alpha0.parquet\",\n",
    "    TESTD/\"x_test_ood.parquet\",\n",
    "    TESTD/\"x_test_ood_base_with_ret.parquet\",\n",
    "    TESTD/\"x_test_ood_base.parquet\",\n",
    "]\n",
    "for _p in OOD_PARQUET_CAND:\n",
    "    if _p.exists():\n",
    "        OOD_PARQUET = _p; break\n",
    "else:\n",
    "    raise FileNotFoundError(\"No OOD parquet found in /test.\")\n",
    "\n",
    "print(\"TRAIN:\", TRAIN_PARQUET)\n",
    "print(\"OOD  :\", OOD_PARQUET)\n",
    "\n",
    "train = pd.read_parquet(TRAIN_PARQUET).sort_values(\"Date\").reset_index(drop=True)\n",
    "ood   = pd.read_parquet(OOD_PARQUET).sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "def realized_return_column(df):\n",
    "    if \"Daily_Return\" in df.columns and pd.api.types.is_numeric_dtype(df[\"Daily_Return\"]): return \"Daily_Return\"\n",
    "    for c in [\"ret\",\"RET\",\"strategy_return\",\"realized_return\"]:\n",
    "        if c in df.columns and pd.api.types.is_numeric_dtype(df[c]): return c\n",
    "    return None\n",
    "\n",
    "def trading_metrics(y_true, y_pred, realized_ret):\n",
    "    if realized_ret is None or len(realized_ret)==0:\n",
    "        return {\"win_rate\": None, \"profit_factor\": None, \"sharpe_252\": None}\n",
    "    pos = np.where(np.asarray(y_pred)>0, 1.0, -1.0)\n",
    "    strat_ret = pos * np.asarray(realized_ret)\n",
    "    win_rate = float((strat_ret>0).mean())\n",
    "    gp = strat_ret[strat_ret>0].sum(); gl = -strat_ret[strat_ret<0].sum()\n",
    "    pf = float(gp/gl) if gl>0 else np.inf\n",
    "    mu, sd = strat_ret.mean(), strat_ret.std(ddof=1)\n",
    "    sharpe = float((mu/sd)*np.sqrt(252)) if sd>0 else np.nan\n",
    "    return {\"win_rate\":win_rate,\"profit_factor\":pf,\"sharpe_252\":sharpe}\n",
    "\n",
    "# --- feature selectors ---\n",
    "def pick_text_col(df):\n",
    "    if \"text_embed\" not in df.columns: raise KeyError(\"text_embed missing\")\n",
    "    return \"text_embed\"\n",
    "\n",
    "def pick_numeric_no_macro(df):\n",
    "    drop = {\"Date\",\"Movement\",\"text_embed\",\"z_retr\",\n",
    "            \"cpi_yoy_lagged_z\",\"unrate_lagged_z\",\"t10y2y_lagged_z\",\"gdp_qoq_lagged_z\",\n",
    "            \"Daily_Return\"}\n",
    "    keep = [c for c in df.columns if c not in drop and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    return keep\n",
    "\n",
    "text_col = pick_text_col(train)\n",
    "num_cols = pick_numeric_no_macro(train)\n",
    "print(\"Numerics (no macro_z) count:\", len(num_cols), \"| text col:\", text_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "42d1e5a4-70e6-4e95-bff0-907eaeafe467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def to_unit_rows(M):\n",
    "    M = M.astype(\"float32\")\n",
    "    nrm = np.linalg.norm(M, axis=1, keepdims=True) + 1e-9\n",
    "    return M / nrm\n",
    "\n",
    "def build_faiss_index(vecs, use_gpu=True):\n",
    "    # IndexFlatIP over L2-normalized vectors => cosine similarity\n",
    "    d = vecs.shape[1]\n",
    "    cpu_index = faiss.IndexFlatIP(d)\n",
    "    if use_gpu and faiss.get_num_gpus()>0:\n",
    "        res = faiss.StandardGpuResources()\n",
    "        return faiss.index_cpu_to_gpu(res, 0, cpu_index), True\n",
    "    return cpu_index, False\n",
    "\n",
    "def compute_zretr(query_text, ref_text, ref_dates, query_dates, K=5, batch=512, use_gpu=True):\n",
    "    \"\"\"\n",
    "    α=0 -> queries = normalized text only. ref_text are normalized text of ref set.\n",
    "    Causal mask: ref_date < query_date. Aggregate neighbor TEXT into z_retr (mean).\n",
    "    \"\"\"\n",
    "    q = to_unit_rows(query_text)\n",
    "    r = to_unit_rows(ref_text)\n",
    "\n",
    "    index, gpu = build_faiss_index(r, use_gpu=use_gpu)\n",
    "    index.add(r)\n",
    "\n",
    "    z = np.zeros((q.shape[0], r.shape[1]), dtype=\"float32\")\n",
    "    effk = []\n",
    "    for s in range(0, q.shape[0], batch):\n",
    "        e = min(s+batch, q.shape[0])\n",
    "        D, I = index.search(q[s:e], K*10)  # oversample for mask\n",
    "        for i in range(s, e):\n",
    "            cand = I[i-s]\n",
    "            mask = (ref_dates[cand] < query_dates[i])\n",
    "            pick = np.where(mask)[0][:K]\n",
    "            if pick.size==0:  # fallback\n",
    "                pick = np.arange(min(K, len(cand)))\n",
    "            ids = cand[pick]\n",
    "            z[i] = r[ids].mean(axis=0)  # mean of TEXT neighbors\n",
    "            effk.append(len(ids))\n",
    "    return z, np.array(effk, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0e0a66c-dcc5-4e88-a1ac-371aa838a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Text-Ret (α=0) CV results (per fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>n_val</th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "      <th>effK_tr_min</th>\n",
       "      <th>effK_tr_med</th>\n",
       "      <th>effK_tr_max</th>\n",
       "      <th>effK_va_min</th>\n",
       "      <th>effK_va_med</th>\n",
       "      <th>effK_va_max</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>WinRate</th>\n",
       "      <th>ProfitFactor</th>\n",
       "      <th>Sharpe_252</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>466</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.645923</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.596577</td>\n",
       "      <td>0.360100</td>\n",
       "      <td>0.762173</td>\n",
       "      <td>0.628755</td>\n",
       "      <td>2.342203</td>\n",
       "      <td>4.800363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.538627</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.956175</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>0.620680</td>\n",
       "      <td>0.454936</td>\n",
       "      <td>0.820596</td>\n",
       "      <td>-1.066191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.641631</td>\n",
       "      <td>0.625592</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.759712</td>\n",
       "      <td>0.249950</td>\n",
       "      <td>0.775456</td>\n",
       "      <td>0.515021</td>\n",
       "      <td>1.263594</td>\n",
       "      <td>1.275705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673820</td>\n",
       "      <td>0.652874</td>\n",
       "      <td>0.996491</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.317312</td>\n",
       "      <td>0.829078</td>\n",
       "      <td>0.590129</td>\n",
       "      <td>2.270160</td>\n",
       "      <td>3.703691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>466</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.517167</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.153497</td>\n",
       "      <td>0.841839</td>\n",
       "      <td>0.459227</td>\n",
       "      <td>0.928380</td>\n",
       "      <td>-0.449937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  n_val   val_start     val_end  effK_tr_min  effK_tr_med  effK_tr_max  effK_va_min  effK_va_med  effK_va_max  Accuracy  Precision    Recall        F1  \\\n",
       "0     1    466  2012-09-07  2015-12-03            1          5.0            5            5          5.0            5  0.645923   0.818792  0.469231  0.596577   \n",
       "1     2    466  2015-12-04  2017-10-17            1          5.0            5            5          5.0            5  0.538627   0.540541  0.956175  0.690647   \n",
       "2     3    466  2017-10-18  2019-10-03            1          5.0            5            5          5.0            5  0.641631   0.625592  0.967033  0.759712   \n",
       "3     4    466  2019-10-04  2021-08-26            1          5.0            5            5          5.0            5  0.673820   0.652874  0.996491  0.788889   \n",
       "4     5    466  2021-08-27  2023-07-12            1          5.0            5            5          5.0            5  0.517167   0.505495  1.000000  0.671533   \n",
       "\n",
       "        MCC     AUROC   WinRate  ProfitFactor  Sharpe_252  \n",
       "0  0.360100  0.762173  0.628755      2.342203    4.800363  \n",
       "1  0.017248  0.620680  0.454936      0.820596   -1.066191  \n",
       "2  0.249950  0.775456  0.515021      1.263594    1.275705  \n",
       "3  0.317312  0.829078  0.590129      2.270160    3.703691  \n",
       "4  0.153497  0.841839  0.459227      0.928380   -0.449937  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Text-Ret (α=0) CV means ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy        0.603433\n",
       "Precision       0.628659\n",
       "Recall          0.877786\n",
       "F1              0.701472\n",
       "MCC             0.219621\n",
       "AUROC           0.765845\n",
       "WinRate         0.529614\n",
       "ProfitFactor    1.524987\n",
       "Sharpe_252      1.652726\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_rows = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), 1):\n",
    "    tr_df, va_df = train.iloc[tr_idx].copy(), train.iloc[va_idx].copy()\n",
    "\n",
    "    # --- Build reference (fold-train) once for this fold ---\n",
    "    ref_text  = np.vstack(tr_df[text_col].to_numpy()).astype(\"float32\")\n",
    "    ref_dates = tr_df[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "    # --- z_retr for TRAIN (causal within fold-train) ---\n",
    "    z_tr, effk_tr = compute_zretr(\n",
    "        query_text = ref_text,\n",
    "        ref_text   = ref_text,\n",
    "        ref_dates  = ref_dates,\n",
    "        query_dates= ref_dates,\n",
    "        K=5, batch=512, use_gpu=True\n",
    "    )\n",
    "\n",
    "    # --- z_retr for VAL (query fold-val against fold-train reference) ---\n",
    "    qry_text  = np.vstack(va_df[text_col].to_numpy()).astype(\"float32\")\n",
    "    qry_dates = va_df[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "    z_va, effk_va = compute_zretr(\n",
    "        query_text = qry_text,\n",
    "        ref_text   = ref_text,\n",
    "        ref_dates  = ref_dates,\n",
    "        query_dates= qry_dates,\n",
    "        K=5, batch=512, use_gpu=True\n",
    "    )\n",
    "\n",
    "    # --- Numerics (no macro) scaling ---\n",
    "    Xnum_tr = tr_df[num_cols].to_numpy(dtype=float)\n",
    "    Xnum_va = va_df[num_cols].to_numpy(dtype=float)\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xnum_tr_s = scaler.fit_transform(Xnum_tr)\n",
    "    Xnum_va_s = scaler.transform(Xnum_va)\n",
    "\n",
    "    # --- Text ---\n",
    "    Xtxt_tr = ref_text\n",
    "    Xtxt_va = qry_text\n",
    "\n",
    "    # --- Final design matrices: [scaled numerics | text | z_retr] ---\n",
    "    X_tr = np.hstack([Xnum_tr_s, Xtxt_tr, z_tr]).astype(\"float32\")\n",
    "    X_va = np.hstack([Xnum_va_s, Xtxt_va, z_va]).astype(\"float32\")\n",
    "    y_tr = tr_df[\"Movement\"].to_numpy()\n",
    "    y_va = va_df[\"Movement\"].to_numpy()\n",
    "\n",
    "    # --- Classifier ---\n",
    "    clf = LogisticRegression(max_iter=1000, solver=\"liblinear\", n_jobs=1, random_state=42)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    proba_va = clf.predict_proba(X_va)[:, 1]\n",
    "    yhat_va  = (proba_va >= 0.5).astype(int)\n",
    "\n",
    "    # --- Metrics ---\n",
    "    acc  = accuracy_score(y_va, yhat_va)\n",
    "    prec = precision_score(y_va, yhat_va, zero_division=0)\n",
    "    rec  = recall_score(y_va, yhat_va, zero_division=0)\n",
    "    f1   = f1_score(y_va, yhat_va, zero_division=0)\n",
    "    mcc  = matthews_corrcoef(y_va, yhat_va)\n",
    "    try:\n",
    "        auroc = roc_auc_score(y_va, proba_va)\n",
    "    except ValueError:\n",
    "        auroc = np.nan\n",
    "    rr_col = realized_return_column(va_df)\n",
    "    tm = trading_metrics(y_va, yhat_va, va_df[rr_col].to_numpy() if rr_col else None)\n",
    "\n",
    "    cv_rows.append({\n",
    "        \"fold\": fold, \"n_val\": len(va_df),\n",
    "        \"val_start\": va_df[\"Date\"].min().date(), \"val_end\": va_df[\"Date\"].max().date(),\n",
    "        \"effK_tr_min\": int(effk_tr.min()), \"effK_tr_med\": float(np.median(effk_tr)), \"effK_tr_max\": int(effk_tr.max()),\n",
    "        \"effK_va_min\": int(effk_va.min()), \"effK_va_med\": float(np.median(effk_va)), \"effK_va_max\": int(effk_va.max()),\n",
    "        \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"MCC\": mcc, \"AUROC\": auroc,\n",
    "        \"WinRate\": tm[\"win_rate\"], \"ProfitFactor\": tm[\"profit_factor\"], \"Sharpe_252\": tm[\"sharpe_252\"]\n",
    "    })\n",
    "\n",
    "cv_textret = pd.DataFrame(cv_rows)\n",
    "print(\"\\n=== Text-Ret (α=0) CV results (per fold) ===\")\n",
    "display(cv_textret)\n",
    "\n",
    "print(\"\\n=== Text-Ret (α=0) CV means ===\")\n",
    "display(cv_textret[[\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"MCC\",\"AUROC\",\"WinRate\",\"ProfitFactor\",\"Sharpe_252\"]]\n",
    "        .mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8fa5e2e-c724-4f35-be91-7a2516776463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-train effK stats: 1 5.0 5\n",
      "OOD effK stats: 5 5.0 5\n",
      "\n",
      "=== OOD (AAPL 2024) — Text-Ret (α=0) LR ===\n",
      "Rows: 227 Date range: 2024-01-09 → 2024-12-09\n",
      "Accuracy: 0.4273 | Precision: 0.4259 | Recall: 0.9388 | F1: 0.5860 | MCC: -0.0518 | AUROC: 0.5247\n",
      "WinRate: 0.4053 | ProfitFactor: 0.7517 | Sharpe_252: -1.6300 | ReturnCol: Daily_Return\n"
     ]
    }
   ],
   "source": [
    "# --- Full-train z_retr (causal within full train) ---\n",
    "ref_text_full  = np.vstack(train[text_col].to_numpy()).astype(\"float32\")\n",
    "ref_dates_full = train[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "z_tr_full, effk_full = compute_zretr(\n",
    "    query_text = ref_text_full,\n",
    "    ref_text   = ref_text_full,\n",
    "    ref_dates  = ref_dates_full,\n",
    "    query_dates= ref_dates_full,\n",
    "    K=5, batch=1024, use_gpu=True\n",
    ")\n",
    "print(\"Full-train effK stats:\", effk_full.min(), np.median(effk_full), effk_full.max())\n",
    "\n",
    "# --- Build full-train matrices ---\n",
    "Xnum_full = train[num_cols].to_numpy(dtype=float)\n",
    "scaler_full = StandardScaler(with_mean=True, with_std=True).fit(Xnum_full)\n",
    "Xnum_full_s = scaler_full.transform(Xnum_full)\n",
    "Xtxt_full   = ref_text_full\n",
    "\n",
    "X_full = np.hstack([Xnum_full_s, Xtxt_full, z_tr_full]).astype(\"float32\")\n",
    "y_full = train[\"Movement\"].to_numpy()\n",
    "\n",
    "clf_full = LogisticRegression(max_iter=2000, solver=\"liblinear\", n_jobs=1, random_state=42).fit(X_full, y_full)\n",
    "\n",
    "# --- OOD: compute z_retr α=0 against FULL TRAIN (causal to OOD dates) ---\n",
    "qry_text_ood  = np.vstack(ood[text_col].to_numpy()).astype(\"float32\")\n",
    "qry_dates_ood = ood[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "z_ood, effk_ood = compute_zretr(\n",
    "    query_text = qry_text_ood,\n",
    "    ref_text   = ref_text_full,\n",
    "    ref_dates  = ref_dates_full,\n",
    "    query_dates= qry_dates_ood,\n",
    "    K=5, batch=1024, use_gpu=True\n",
    ")\n",
    "print(\"OOD effK stats:\", effk_ood.min(), np.median(effk_ood), effk_ood.max())\n",
    "\n",
    "# --- OOD design matrix ---\n",
    "Xnum_test = ood[num_cols].to_numpy(dtype=float)\n",
    "Xtxt_test = qry_text_ood\n",
    "X_test = np.hstack([scaler_full.transform(Xnum_test), Xtxt_test, z_ood]).astype(\"float32\")\n",
    "y_test = ood[\"Movement\"].to_numpy()\n",
    "\n",
    "proba_test = clf_full.predict_proba(X_test)[:, 1]\n",
    "yhat_test  = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "# --- Metrics ---\n",
    "acc  = accuracy_score(y_test, yhat_test)\n",
    "prec = precision_score(y_test, yhat_test, zero_division=0)\n",
    "rec  = recall_score(y_test, yhat_test, zero_division=0)\n",
    "f1   = f1_score(y_test, yhat_test, zero_division=0)\n",
    "mcc  = matthews_corrcoef(y_test, yhat_test)\n",
    "try:\n",
    "    auroc = roc_auc_score(y_test, proba_test)\n",
    "except ValueError:\n",
    "    auroc = np.nan\n",
    "\n",
    "rr_col_test = realized_return_column(ood)\n",
    "tm = trading_metrics(y_test, yhat_test, ood[rr_col_test].to_numpy() if rr_col_test else None)\n",
    "\n",
    "print(\"\\n=== OOD (AAPL 2024) — Text-Ret (α=0) LR ===\")\n",
    "print(\"Rows:\", len(ood), \"Date range:\", ood[\"Date\"].min().date(), \"→\", ood[\"Date\"].max().date())\n",
    "print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | MCC: {mcc:.4f} | AUROC: {auroc:.4f}\")\n",
    "if rr_col_test:\n",
    "    print(f\"WinRate: {tm['win_rate']:.4f} | ProfitFactor: {tm['profit_factor']:.4f} | Sharpe_252: {tm['sharpe_252']:.4f} | ReturnCol: {rr_col_test}\")\n",
    "else:\n",
    "    print(\"No realized-return column found in OOD; trading metrics skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c14944-2651-4975-ade2-619db29d0e74",
   "metadata": {},
   "source": [
    "# Macro Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3be81e6b-f7f1-44ce-afa3-69e725de5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "ALPHA = 0.5        # try {0.25, 0.5, 1.0}\n",
    "K = 5              # try {3,5,10}\n",
    "BATCH = 512\n",
    "USE_GPU = True\n",
    "\n",
    "MACRO_COLS = [\"cpi_yoy_lagged_z\",\"unrate_lagged_z\",\"t10y2y_lagged_z\",\"gdp_qoq_lagged_z\"]\n",
    "text_col  = \"text_embed\"\n",
    "\n",
    "def to_unit_rows(M):\n",
    "    M = M.astype(\"float32\")\n",
    "    return M / (np.linalg.norm(M, axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "def make_joint(text_mat, macro_mat, alpha):\n",
    "    # [text ; α * macro] then L2-normalize → dim = 384 + 4\n",
    "    joint = np.concatenate([text_mat.astype(\"float32\"), (alpha * macro_mat.astype(\"float32\"))], axis=1)\n",
    "    return to_unit_rows(joint)\n",
    "\n",
    "import faiss\n",
    "def build_flat_ip(d, use_gpu=True):\n",
    "    idx = faiss.IndexFlatIP(d)\n",
    "    if use_gpu and faiss.get_num_gpus() > 0:\n",
    "        res = faiss.StandardGpuResources()\n",
    "        return faiss.index_cpu_to_gpu(res, 0, idx), True\n",
    "    return idx, False\n",
    "\n",
    "def z_retr_from_joint(q_joint, r_joint, r_text, r_dates, q_dates, K=5, batch=512, use_gpu=True):\n",
    "    # r_joint is the FAISS index vectors (normalized joint); r_text aggregated for z_retr\n",
    "    d = r_joint.shape[1]\n",
    "    index, gpu = build_flat_ip(d, use_gpu)\n",
    "    index.add(r_joint)\n",
    "\n",
    "    Z = np.zeros((q_joint.shape[0], r_text.shape[1]), dtype=\"float32\")\n",
    "    effK = []\n",
    "\n",
    "    for s in range(0, q_joint.shape[0], batch):\n",
    "        e = min(s+batch, q_joint.shape[0])\n",
    "        D, I = index.search(q_joint[s:e], K*10)  # oversample then causal-mask\n",
    "        for i in range(s, e):\n",
    "            cand = I[i-s]\n",
    "            mask = (r_dates[cand] < q_dates[i])\n",
    "            pick = np.where(mask)[0][:K]\n",
    "            if pick.size == 0:\n",
    "                pick = np.arange(min(K, len(cand)))\n",
    "            ids = cand[pick]\n",
    "            Z[i] = r_text[ids].mean(axis=0)\n",
    "            effK.append(len(ids))\n",
    "    return Z, np.array(effK, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e00939f2-0837-4c80-9cf2-cf5f0e1b7d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerics+macro count: 12\n",
      "\n",
      "=== Macro-Ret (α=0.5) CV results (per fold) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>n_val</th>\n",
       "      <th>effK_tr_min</th>\n",
       "      <th>effK_tr_med</th>\n",
       "      <th>effK_tr_max</th>\n",
       "      <th>effK_va_min</th>\n",
       "      <th>effK_va_med</th>\n",
       "      <th>effK_va_max</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>WinRate</th>\n",
       "      <th>ProfitFactor</th>\n",
       "      <th>Sharpe_252</th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>466</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.637339</td>\n",
       "      <td>0.608592</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.751105</td>\n",
       "      <td>0.304523</td>\n",
       "      <td>0.751998</td>\n",
       "      <td>0.585837</td>\n",
       "      <td>1.802533</td>\n",
       "      <td>3.348370</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>2015-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.546697</td>\n",
       "      <td>0.956175</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.065280</td>\n",
       "      <td>0.602594</td>\n",
       "      <td>0.457082</td>\n",
       "      <td>0.899747</td>\n",
       "      <td>-0.570059</td>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>2017-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673820</td>\n",
       "      <td>0.653944</td>\n",
       "      <td>0.941392</td>\n",
       "      <td>0.771772</td>\n",
       "      <td>0.320814</td>\n",
       "      <td>0.769098</td>\n",
       "      <td>0.530043</td>\n",
       "      <td>1.289516</td>\n",
       "      <td>1.386096</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>2019-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.669528</td>\n",
       "      <td>0.663342</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.263743</td>\n",
       "      <td>0.673704</td>\n",
       "      <td>0.568670</td>\n",
       "      <td>1.966396</td>\n",
       "      <td>3.081678</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>2021-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>466</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.587983</td>\n",
       "      <td>0.546341</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.784433</td>\n",
       "      <td>0.508584</td>\n",
       "      <td>1.320267</td>\n",
       "      <td>1.680882</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>2023-07-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  n_val  effK_tr_min  effK_tr_med  effK_tr_max  effK_va_min  effK_va_med  effK_va_max  Accuracy  Precision    Recall        F1       MCC     AUROC  \\\n",
       "0     1    466            1          5.0            5            5          5.0            5  0.637339   0.608592  0.980769  0.751105  0.304523  0.751998   \n",
       "1     2    466            1          5.0            5            5          5.0            5  0.549356   0.546697  0.956175  0.695652  0.065280  0.602594   \n",
       "2     3    466            1          5.0            5            5          5.0            5  0.673820   0.653944  0.941392  0.771772  0.320814  0.769098   \n",
       "3     4    466            1          5.0            5            5          5.0            5  0.669528   0.663342  0.933333  0.775510  0.263743  0.673704   \n",
       "4     5    466            1          5.0            5            5          5.0            5  0.587983   0.546341  0.973913  0.700000  0.285645  0.784433   \n",
       "\n",
       "    WinRate  ProfitFactor  Sharpe_252   val_start     val_end  \n",
       "0  0.585837      1.802533    3.348370  2012-09-07  2015-12-03  \n",
       "1  0.457082      0.899747   -0.570059  2015-12-04  2017-10-17  \n",
       "2  0.530043      1.289516    1.386096  2017-10-18  2019-10-03  \n",
       "3  0.568670      1.966396    3.081678  2019-10-04  2021-08-26  \n",
       "4  0.508584      1.320267    1.680882  2021-08-27  2023-07-12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Macro-Ret (α=0.5) CV means ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy        0.623605\n",
       "Precision       0.603783\n",
       "Recall          0.957117\n",
       "F1              0.738808\n",
       "MCC             0.248001\n",
       "AUROC           0.716365\n",
       "WinRate         0.530043\n",
       "ProfitFactor    1.455692\n",
       "Sharpe_252      1.785393\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use numerics + macro_z\n",
    "def pick_numeric_incl_macro(df):\n",
    "    drop = {\"Date\",\"Movement\",\"z_retr\",\"Daily_Return\",\"text_embed\"}\n",
    "    keep = [c for c in df.columns if c not in drop and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    return keep\n",
    "\n",
    "num_cols = pick_numeric_incl_macro(train)\n",
    "print(\"Numerics+macro count:\", len(num_cols))\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rows = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), 1):\n",
    "    tr_df, va_df = train.iloc[tr_idx].copy(), train.iloc[va_idx].copy()\n",
    "\n",
    "    # Reference (fold-train)\n",
    "    R_text  = np.vstack(tr_df[text_col].to_numpy()).astype(\"float32\")\n",
    "    R_macro = tr_df[MACRO_COLS].to_numpy().astype(\"float32\")\n",
    "    R_joint = make_joint(R_text, R_macro, ALPHA)\n",
    "    R_dates = tr_df[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "    # TRAIN z_retr (causal within fold-train)\n",
    "    Ztr, effK_tr = z_retr_from_joint(\n",
    "        q_joint = R_joint, r_joint = R_joint, r_text = R_text,\n",
    "        r_dates = R_dates, q_dates = R_dates,\n",
    "        K=K, batch=BATCH, use_gpu=USE_GPU\n",
    "    )\n",
    "\n",
    "    # VAL z_retr (query val against fold-train)\n",
    "    Q_text  = np.vstack(va_df[text_col].to_numpy()).astype(\"float32\")\n",
    "    Q_macro = va_df[MACRO_COLS].to_numpy().astype(\"float32\")\n",
    "    Q_joint = make_joint(Q_text, Q_macro, ALPHA)\n",
    "    Q_dates = va_df[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "    Zva, effK_va = z_retr_from_joint(\n",
    "        q_joint = Q_joint, r_joint = R_joint, r_text = R_text,\n",
    "        r_dates = R_dates, q_dates = Q_dates,\n",
    "        K=K, batch=BATCH, use_gpu=USE_GPU\n",
    "    )\n",
    "\n",
    "    # Build design matrices: [scaled numerics+macro | text | z_retr]\n",
    "    Xnum_tr = tr_df[num_cols].to_numpy(dtype=float)\n",
    "    Xnum_va = va_df[num_cols].to_numpy(dtype=float)\n",
    "    scaler  = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xnum_tr_s = scaler.fit_transform(Xnum_tr)\n",
    "    Xnum_va_s = scaler.transform(Xnum_va)\n",
    "\n",
    "    Xtxt_tr = R_text\n",
    "    Xtxt_va = Q_text\n",
    "\n",
    "    X_tr = np.hstack([Xnum_tr_s, Xtxt_tr, Ztr]).astype(\"float32\")\n",
    "    X_va = np.hstack([Xnum_va_s, Xtxt_va, Zva]).astype(\"float32\")\n",
    "    y_tr = tr_df[\"Movement\"].to_numpy()\n",
    "    y_va = va_df[\"Movement\"].to_numpy()\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, solver=\"liblinear\", n_jobs=1, random_state=42)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    proba_va = clf.predict_proba(X_va)[:, 1]\n",
    "    yhat_va  = (proba_va >= 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc  = accuracy_score(y_va, yhat_va)\n",
    "    prec = precision_score(y_va, yhat_va, zero_division=0)\n",
    "    rec  = recall_score(y_va, yhat_va, zero_division=0)\n",
    "    f1   = f1_score(y_va, yhat_va, zero_division=0)\n",
    "    mcc  = matthews_corrcoef(y_va, yhat_va)\n",
    "    try:\n",
    "        auroc = roc_auc_score(y_va, proba_va)\n",
    "    except ValueError:\n",
    "        auroc = np.nan\n",
    "    rr_col = realized_return_column(va_df)\n",
    "    tm = trading_metrics(y_va, yhat_va, va_df[rr_col].to_numpy() if rr_col else None)\n",
    "\n",
    "    rows.append({\n",
    "        \"fold\": fold, \"n_val\": len(va_df),\n",
    "        \"effK_tr_min\": int(effK_tr.min()), \"effK_tr_med\": float(np.median(effK_tr)), \"effK_tr_max\": int(effK_tr.max()),\n",
    "        \"effK_va_min\": int(effK_va.min()), \"effK_va_med\": float(np.median(effK_va)), \"effK_va_max\": int(effK_va.max()),\n",
    "        \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"MCC\": mcc, \"AUROC\": auroc,\n",
    "        \"WinRate\": tm[\"win_rate\"], \"ProfitFactor\": tm[\"profit_factor\"], \"Sharpe_252\": tm[\"sharpe_252\"],\n",
    "        \"val_start\": va_df[\"Date\"].min().date(), \"val_end\": va_df[\"Date\"].max().date()\n",
    "    })\n",
    "\n",
    "cv_macroret = pd.DataFrame(rows)\n",
    "print(\"\\n=== Macro-Ret (α={}) CV results (per fold) ===\".format(ALPHA))\n",
    "display(cv_macroret)\n",
    "\n",
    "print(\"\\n=== Macro-Ret (α={}) CV means ===\".format(ALPHA))\n",
    "display(cv_macroret[[\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"MCC\",\"AUROC\",\"WinRate\",\"ProfitFactor\",\"Sharpe_252\"]]\n",
    "        .mean(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "14556402-5914-45d4-8d30-0873a55bba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-train effK stats: 1 5.0 5\n",
      "OOD effK stats: 5 5.0 5\n",
      "\n",
      "=== OOD (AAPL 2024) — Macro-Ret (α=0.5) LR ===\n",
      "Rows: 227 Date range: 2024-01-09 → 2024-12-09\n",
      "Accuracy: 0.4537 | Precision: 0.4097 | Recall: 0.6020 | F1: 0.4876 | MCC: -0.0585 | AUROC: 0.4994\n",
      "WinRate: 0.4581 | ProfitFactor: 1.1043 | Sharpe_252: 0.5671 | ReturnCol: Daily_Return\n"
     ]
    }
   ],
   "source": [
    "# Full-train reference\n",
    "R_text_full  = np.vstack(train[text_col].to_numpy()).astype(\"float32\")\n",
    "R_macro_full = train[MACRO_COLS].to_numpy().astype(\"float32\")\n",
    "R_joint_full = make_joint(R_text_full, R_macro_full, ALPHA)\n",
    "R_dates_full = train[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "# Full-train z_retr (causal)\n",
    "Ztr_full, effK_full = z_retr_from_joint(\n",
    "    q_joint = R_joint_full, r_joint = R_joint_full, r_text = R_text_full,\n",
    "    r_dates = R_dates_full, q_dates = R_dates_full,\n",
    "    K=K, batch=1024, use_gpu=USE_GPU\n",
    ")\n",
    "print(\"Full-train effK stats:\", effK_full.min(), np.median(effK_full), effK_full.max())\n",
    "\n",
    "# Train matrix\n",
    "Xnum_full  = train[num_cols].to_numpy(dtype=float)\n",
    "scaler_full = StandardScaler(with_mean=True, with_std=True).fit(Xnum_full)\n",
    "Xnum_full_s = scaler_full.transform(Xnum_full)\n",
    "X_full = np.hstack([Xnum_full_s, R_text_full, Ztr_full]).astype(\"float32\")\n",
    "y_full = train[\"Movement\"].to_numpy()\n",
    "\n",
    "clf_full = LogisticRegression(max_iter=3000, solver=\"liblinear\", n_jobs=1, random_state=42).fit(X_full, y_full)\n",
    "\n",
    "# OOD z_retr with joint queries (macro-aware)\n",
    "Q_text_ood  = np.vstack(ood[text_col].to_numpy()).astype(\"float32\")\n",
    "Q_macro_ood = ood[MACRO_COLS].to_numpy().astype(\"float32\")\n",
    "Q_joint_ood = make_joint(Q_text_ood, Q_macro_ood, ALPHA)\n",
    "Q_dates_ood = ood[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "Z_ood, effK_ood = z_retr_from_joint(\n",
    "    q_joint = Q_joint_ood, r_joint = R_joint_full, r_text = R_text_full,\n",
    "    r_dates = R_dates_full, q_dates = Q_dates_ood,\n",
    "    K=K, batch=1024, use_gpu=USE_GPU\n",
    ")\n",
    "print(\"OOD effK stats:\", effK_ood.min(), np.median(effK_ood), effK_ood.max())\n",
    "\n",
    "# OOD matrix\n",
    "Xnum_test  = ood[num_cols].to_numpy(dtype=float)\n",
    "Xnum_test_s = scaler_full.transform(Xnum_test)\n",
    "X_test = np.hstack([Xnum_test_s, Q_text_ood, Z_ood]).astype(\"float32\")\n",
    "y_test = ood[\"Movement\"].to_numpy()\n",
    "\n",
    "proba_test = clf_full.predict_proba(X_test)[:, 1]\n",
    "yhat_test  = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "acc  = accuracy_score(y_test, yhat_test)\n",
    "prec = precision_score(y_test, yhat_test, zero_division=0)\n",
    "rec  = recall_score(y_test, yhat_test, zero_division=0)\n",
    "f1   = f1_score(y_test, yhat_test, zero_division=0)\n",
    "mcc  = matthews_corrcoef(y_test, yhat_test)\n",
    "try:\n",
    "    auroc = roc_auc_score(y_test, proba_test)\n",
    "except ValueError:\n",
    "    auroc = np.nan\n",
    "\n",
    "rr_col_test = realized_return_column(ood)\n",
    "tm = trading_metrics(y_test, yhat_test, ood[rr_col_test].to_numpy() if rr_col_test else None)\n",
    "\n",
    "print(\"\\n=== OOD (AAPL 2024) — Macro-Ret (α={}) LR ===\".format(ALPHA))\n",
    "print(\"Rows:\", len(ood), \"Date range:\", ood[\"Date\"].min().date(), \"→\", ood[\"Date\"].max().date())\n",
    "print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | MCC: {mcc:.4f} | AUROC: {auroc:.4f}\")\n",
    "if rr_col_test:\n",
    "    print(f\"WinRate: {tm['win_rate']:.4f} | ProfitFactor: {tm['profit_factor']:.4f} | Sharpe_252: {tm['sharpe_252']:.4f} | ReturnCol: {rr_col_test}\")\n",
    "else:\n",
    "    print(\"No realized-return column found in OOD; trading metrics skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4675de5-53be-40c5-aa3b-bb98e6133ddb",
   "metadata": {},
   "source": [
    "# Alpha Sweep (α ∈ {0.25, 0.5, 1.0}) × (K ∈ {3,5,10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "92c7d985-374c-43e7-96c6-1779e452251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running Macro-Ret sweep: alpha=0.25, K=3\n",
      "\n",
      ">>> Running Macro-Ret sweep: alpha=0.25, K=5\n",
      "\n",
      ">>> Running Macro-Ret sweep: alpha=0.25, K=10\n",
      "\n",
      ">>> Running Macro-Ret sweep: alpha=0.5, K=3\n",
      "\n",
      ">>> Running Macro-Ret sweep: alpha=0.5, K=5\n",
      "\n",
      ">>> Running Macro-Ret sweep: alpha=0.5, K=10\n",
      "\n",
      ">>> Running Macro-Ret sweep: alpha=1.0, K=3\n",
      "\n",
      ">>> Running Macro-Ret sweep: alpha=1.0, K=5\n",
      "\n",
      ">>> Running Macro-Ret sweep: alpha=1.0, K=10\n",
      "\n",
      "=== Sweep summary (sorted by OOD Sharpe) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>K</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Precision</th>\n",
       "      <th>CV_Recall</th>\n",
       "      <th>CV_F1</th>\n",
       "      <th>CV_MCC</th>\n",
       "      <th>CV_AUROC</th>\n",
       "      <th>CV_WinRate</th>\n",
       "      <th>CV_ProfitFactor</th>\n",
       "      <th>CV_Sharpe_252</th>\n",
       "      <th>OOD_Accuracy</th>\n",
       "      <th>OOD_Precision</th>\n",
       "      <th>OOD_Recall</th>\n",
       "      <th>OOD_F1</th>\n",
       "      <th>OOD_MCC</th>\n",
       "      <th>OOD_AUROC</th>\n",
       "      <th>OOD_WinRate</th>\n",
       "      <th>OOD_ProfitFactor</th>\n",
       "      <th>OOD_Sharpe_252</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.623605</td>\n",
       "      <td>0.603783</td>\n",
       "      <td>0.957117</td>\n",
       "      <td>0.738808</td>\n",
       "      <td>0.248001</td>\n",
       "      <td>0.716365</td>\n",
       "      <td>0.530043</td>\n",
       "      <td>1.455692</td>\n",
       "      <td>1.785393</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.487603</td>\n",
       "      <td>-0.058493</td>\n",
       "      <td>0.499367</td>\n",
       "      <td>0.458150</td>\n",
       "      <td>1.104282</td>\n",
       "      <td>0.567124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>0.626180</td>\n",
       "      <td>0.604290</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>0.740596</td>\n",
       "      <td>0.249039</td>\n",
       "      <td>0.718346</td>\n",
       "      <td>0.536052</td>\n",
       "      <td>1.488445</td>\n",
       "      <td>1.937222</td>\n",
       "      <td>0.449339</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.513619</td>\n",
       "      <td>-0.051320</td>\n",
       "      <td>0.496124</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0.512946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.624034</td>\n",
       "      <td>0.604152</td>\n",
       "      <td>0.957408</td>\n",
       "      <td>0.739148</td>\n",
       "      <td>0.246426</td>\n",
       "      <td>0.716644</td>\n",
       "      <td>0.528755</td>\n",
       "      <td>1.459990</td>\n",
       "      <td>1.829276</td>\n",
       "      <td>0.449339</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.513619</td>\n",
       "      <td>-0.051320</td>\n",
       "      <td>0.493672</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0.512946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.627897</td>\n",
       "      <td>0.605758</td>\n",
       "      <td>0.958278</td>\n",
       "      <td>0.741109</td>\n",
       "      <td>0.257208</td>\n",
       "      <td>0.713381</td>\n",
       "      <td>0.536910</td>\n",
       "      <td>1.504190</td>\n",
       "      <td>1.944361</td>\n",
       "      <td>0.462555</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.519685</td>\n",
       "      <td>-0.025860</td>\n",
       "      <td>0.499130</td>\n",
       "      <td>0.458150</td>\n",
       "      <td>1.065882</td>\n",
       "      <td>0.364815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.623176</td>\n",
       "      <td>0.603068</td>\n",
       "      <td>0.957818</td>\n",
       "      <td>0.738680</td>\n",
       "      <td>0.246295</td>\n",
       "      <td>0.714433</td>\n",
       "      <td>0.531330</td>\n",
       "      <td>1.485478</td>\n",
       "      <td>1.908600</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>-0.038136</td>\n",
       "      <td>0.498813</td>\n",
       "      <td>0.449339</td>\n",
       "      <td>1.057860</td>\n",
       "      <td>0.321620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.625751</td>\n",
       "      <td>0.603034</td>\n",
       "      <td>0.961876</td>\n",
       "      <td>0.740496</td>\n",
       "      <td>0.254257</td>\n",
       "      <td>0.716197</td>\n",
       "      <td>0.535622</td>\n",
       "      <td>1.477151</td>\n",
       "      <td>1.896359</td>\n",
       "      <td>0.466960</td>\n",
       "      <td>0.431138</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.543396</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>0.500475</td>\n",
       "      <td>0.444934</td>\n",
       "      <td>1.035376</td>\n",
       "      <td>0.198787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.630472</td>\n",
       "      <td>0.606693</td>\n",
       "      <td>0.959265</td>\n",
       "      <td>0.742455</td>\n",
       "      <td>0.264952</td>\n",
       "      <td>0.716912</td>\n",
       "      <td>0.532618</td>\n",
       "      <td>1.478795</td>\n",
       "      <td>1.920737</td>\n",
       "      <td>0.484581</td>\n",
       "      <td>0.417391</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>-0.029309</td>\n",
       "      <td>0.496361</td>\n",
       "      <td>0.480176</td>\n",
       "      <td>1.028649</td>\n",
       "      <td>0.161516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.627897</td>\n",
       "      <td>0.605536</td>\n",
       "      <td>0.954832</td>\n",
       "      <td>0.740272</td>\n",
       "      <td>0.252135</td>\n",
       "      <td>0.713856</td>\n",
       "      <td>0.535193</td>\n",
       "      <td>1.479797</td>\n",
       "      <td>1.879385</td>\n",
       "      <td>0.475771</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.547529</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.490745</td>\n",
       "      <td>0.444934</td>\n",
       "      <td>1.026318</td>\n",
       "      <td>0.148547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0.619313</td>\n",
       "      <td>0.602059</td>\n",
       "      <td>0.951243</td>\n",
       "      <td>0.735364</td>\n",
       "      <td>0.240531</td>\n",
       "      <td>0.711387</td>\n",
       "      <td>0.525751</td>\n",
       "      <td>1.412177</td>\n",
       "      <td>1.668149</td>\n",
       "      <td>0.466960</td>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.539924</td>\n",
       "      <td>-0.004660</td>\n",
       "      <td>0.495175</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>0.985151</td>\n",
       "      <td>-0.085547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha   K  CV_Accuracy  CV_Precision  CV_Recall     CV_F1    CV_MCC  CV_AUROC  CV_WinRate  CV_ProfitFactor  CV_Sharpe_252  OOD_Accuracy  OOD_Precision  \\\n",
       "4   0.50   5     0.623605      0.603783   0.957117  0.738808  0.248001  0.716365    0.530043         1.455692       1.785393      0.453744       0.409722   \n",
       "2   0.25  10     0.626180      0.604290   0.959702  0.740596  0.249039  0.718346    0.536052         1.488445       1.937222      0.449339       0.415094   \n",
       "5   0.50  10     0.624034      0.604152   0.957408  0.739148  0.246426  0.716644    0.528755         1.459990       1.829276      0.449339       0.415094   \n",
       "6   1.00   3     0.627897      0.605758   0.958278  0.741109  0.257208  0.713381    0.536910         1.504190       1.944361      0.462555       0.423077   \n",
       "7   1.00   5     0.623176      0.603068   0.957818  0.738680  0.246295  0.714433    0.531330         1.485478       1.908600      0.453744       0.419753   \n",
       "1   0.25   5     0.625751      0.603034   0.961876  0.740496  0.254257  0.716197    0.535622         1.477151       1.896359      0.466960       0.431138   \n",
       "3   0.50   3     0.630472      0.606693   0.959265  0.742455  0.264952  0.716912    0.532618         1.478795       1.920737      0.484581       0.417391   \n",
       "0   0.25   3     0.627897      0.605536   0.954832  0.740272  0.252135  0.713856    0.535193         1.479797       1.879385      0.475771       0.436364   \n",
       "8   1.00  10     0.619313      0.602059   0.951243  0.735364  0.240531  0.711387    0.525751         1.412177       1.668149      0.466960       0.430303   \n",
       "\n",
       "   OOD_Recall    OOD_F1   OOD_MCC  OOD_AUROC  OOD_WinRate  OOD_ProfitFactor  OOD_Sharpe_252  \n",
       "4    0.602041  0.487603 -0.058493   0.499367     0.458150          1.104282        0.567124  \n",
       "2    0.673469  0.513619 -0.051320   0.496124     0.453744          1.093864        0.512946  \n",
       "5    0.673469  0.513619 -0.051320   0.493672     0.453744          1.093864        0.512946  \n",
       "6    0.673469  0.519685 -0.025860   0.499130     0.458150          1.065882        0.364815  \n",
       "7    0.693878  0.523077 -0.038136   0.498813     0.449339          1.057860        0.321620  \n",
       "1    0.734694  0.543396 -0.001955   0.500475     0.444934          1.035376        0.198787  \n",
       "3    0.489796  0.450704 -0.029309   0.496361     0.480176          1.028649        0.161516  \n",
       "0    0.734694  0.547529  0.015300   0.490745     0.444934          1.026318        0.148547  \n",
       "8    0.724490  0.539924 -0.004660   0.495175     0.436123          0.985151       -0.085547  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 by OOD Profit Factor:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>K</th>\n",
       "      <th>OOD_ProfitFactor</th>\n",
       "      <th>OOD_Sharpe_252</th>\n",
       "      <th>OOD_WinRate</th>\n",
       "      <th>OOD_AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.104282</td>\n",
       "      <td>0.567124</td>\n",
       "      <td>0.458150</td>\n",
       "      <td>0.499367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>0.496124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>0.493672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha   K  OOD_ProfitFactor  OOD_Sharpe_252  OOD_WinRate  OOD_AUROC\n",
       "4   0.50   5          1.104282        0.567124     0.458150   0.499367\n",
       "2   0.25  10          1.093864        0.512946     0.453744   0.496124\n",
       "5   0.50  10          1.093864        0.512946     0.453744   0.493672"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, matthews_corrcoef, roc_auc_score)\n",
    "\n",
    "ALPHAS = [0.25, 0.5, 1.0]\n",
    "KS     = [3, 5, 10]\n",
    "BATCH  = 512\n",
    "USE_GPU = True\n",
    "\n",
    "MACRO_COLS = [\"cpi_yoy_lagged_z\",\"unrate_lagged_z\",\"t10y2y_lagged_z\",\"gdp_qoq_lagged_z\"]\n",
    "text_col   = \"text_embed\"\n",
    "\n",
    "def pick_numeric_incl_macro(df):\n",
    "    drop = {\"Date\",\"Movement\",\"z_retr\",\"Daily_Return\",\"text_embed\"}\n",
    "    return [c for c in df.columns if c not in drop and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "num_cols = pick_numeric_incl_macro(train)\n",
    "\n",
    "# Pre-materialize arrays once\n",
    "R_TEXT_FULL  = np.vstack(train[text_col].to_numpy()).astype(\"float32\")\n",
    "R_MACRO_FULL = train[MACRO_COLS].to_numpy().astype(\"float32\")\n",
    "R_DATES_FULL = train[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "Q_TEXT_OOD   = np.vstack(ood[text_col].to_numpy()).astype(\"float32\")\n",
    "Q_MACRO_OOD  = ood[MACRO_COLS].to_numpy().astype(\"float32\")\n",
    "Q_DATES_OOD  = ood[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "def run_macroret(alpha, K):\n",
    "    # ---- CV ----\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    cv_metrics = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), 1):\n",
    "        tr_df, va_df = train.iloc[tr_idx].copy(), train.iloc[va_idx].copy()\n",
    "\n",
    "        # Fold reference (train)\n",
    "        R_text  = np.vstack(tr_df[text_col].to_numpy()).astype(\"float32\")\n",
    "        R_macro = tr_df[MACRO_COLS].to_numpy().astype(\"float32\")\n",
    "        R_joint = make_joint(R_text, R_macro, alpha)\n",
    "        R_dates = tr_df[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "        # z_retr for train (causal within train)\n",
    "        Ztr, _ = z_retr_from_joint(R_joint, R_joint, R_text, R_dates, R_dates, K=K, batch=BATCH, use_gpu=USE_GPU)\n",
    "\n",
    "        # z_retr for val (query val vs train)\n",
    "        Q_text = np.vstack(va_df[text_col].to_numpy()).astype(\"float32\")\n",
    "        Q_macro = va_df[MACRO_COLS].to_numpy().astype(\"float32\")\n",
    "        Q_joint = make_joint(Q_text, Q_macro, alpha)\n",
    "        Q_dates = va_df[\"Date\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "        Zva, _ = z_retr_from_joint(Q_joint, R_joint, R_text, R_dates, Q_dates, K=K, batch=BATCH, use_gpu=USE_GPU)\n",
    "\n",
    "        # Design matrices: [scaled numerics+macro | text | z_retr]\n",
    "        Xnum_tr = tr_df[num_cols].to_numpy(dtype=float)\n",
    "        Xnum_va = va_df[num_cols].to_numpy(dtype=float)\n",
    "        scaler  = StandardScaler(with_mean=True, with_std=True).fit(Xnum_tr)\n",
    "        X_tr = np.hstack([scaler.transform(Xnum_tr),\n",
    "                          R_text,\n",
    "                          Ztr]).astype(\"float32\")\n",
    "        X_va = np.hstack([scaler.transform(Xnum_va),\n",
    "                          Q_text,\n",
    "                          Zva]).astype(\"float32\")\n",
    "\n",
    "        y_tr = tr_df[\"Movement\"].to_numpy()\n",
    "        y_va = va_df[\"Movement\"].to_numpy()\n",
    "\n",
    "        clf = LogisticRegression(max_iter=3000, solver=\"liblinear\", n_jobs=1, random_state=42).fit(X_tr, y_tr)\n",
    "        proba_va = clf.predict_proba(X_va)[:, 1]\n",
    "        yhat_va  = (proba_va >= 0.5).astype(int)\n",
    "\n",
    "        # Metrics\n",
    "        acc  = accuracy_score(y_va, yhat_va)\n",
    "        prec = precision_score(y_va, yhat_va, zero_division=0)\n",
    "        rec  = recall_score(y_va, yhat_va, zero_division=0)\n",
    "        f1   = f1_score(y_va, yhat_va, zero_division=0)\n",
    "        mcc  = matthews_corrcoef(y_va, yhat_va)\n",
    "        try: auroc = roc_auc_score(y_va, proba_va)\n",
    "        except ValueError: auroc = np.nan\n",
    "        rr_col = realized_return_column(va_df)\n",
    "        tm = trading_metrics(y_va, yhat_va, va_df[rr_col].to_numpy() if rr_col else None)\n",
    "\n",
    "        cv_metrics.append([acc,prec,rec,f1,mcc,auroc,tm[\"win_rate\"],tm[\"profit_factor\"],tm[\"sharpe_252\"]])\n",
    "\n",
    "    cv_mean = np.nanmean(np.array(cv_metrics, dtype=float), axis=0)\n",
    "    (cv_acc,cv_prec,cv_rec,cv_f1,cv_mcc,cv_auroc,cv_wr,cv_pf,cv_sharpe) = cv_mean\n",
    "\n",
    "    # ---- Full-train → OOD ----\n",
    "    R_joint_full = make_joint(R_TEXT_FULL, R_MACRO_FULL, alpha)\n",
    "    Ztr_full, _  = z_retr_from_joint(R_joint_full, R_joint_full, R_TEXT_FULL, R_DATES_FULL, R_DATES_FULL,\n",
    "                                     K=K, batch=1024, use_gpu=USE_GPU)\n",
    "\n",
    "    Xnum_full   = train[num_cols].to_numpy(dtype=float)\n",
    "    scaler_full = StandardScaler(with_mean=True, with_std=True).fit(Xnum_full)\n",
    "    X_full = np.hstack([scaler_full.transform(Xnum_full),\n",
    "                        R_TEXT_FULL,\n",
    "                        Ztr_full]).astype(\"float32\")\n",
    "    y_full = train[\"Movement\"].to_numpy()\n",
    "\n",
    "    clf_full = LogisticRegression(max_iter=3000, solver=\"liblinear\", n_jobs=1, random_state=42).fit(X_full, y_full)\n",
    "\n",
    "    # OOD z_retr (query OOD vs full train)\n",
    "    Q_joint_ood = make_joint(Q_TEXT_OOD, Q_MACRO_OOD, alpha)\n",
    "    Z_ood, _    = z_retr_from_joint(Q_joint_ood, R_joint_full, R_TEXT_FULL, R_DATES_FULL, Q_DATES_OOD,\n",
    "                                    K=K, batch=1024, use_gpu=USE_GPU)\n",
    "\n",
    "    Xnum_test = ood[num_cols].to_numpy(dtype=float)\n",
    "    X_test = np.hstack([scaler_full.transform(Xnum_test),\n",
    "                        Q_TEXT_OOD,\n",
    "                        Z_ood]).astype(\"float32\")\n",
    "    y_test = ood[\"Movement\"].to_numpy()\n",
    "\n",
    "    proba_test = clf_full.predict_proba(X_test)[:, 1]\n",
    "    yhat_test  = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "    acc  = accuracy_score(y_test, yhat_test)\n",
    "    prec = precision_score(y_test, yhat_test, zero_division=0)\n",
    "    rec  = recall_score(y_test, yhat_test, zero_division=0)\n",
    "    f1   = f1_score(y_test, yhat_test, zero_division=0)\n",
    "    mcc  = matthews_corrcoef(y_test, yhat_test)\n",
    "    try: auroc = roc_auc_score(y_test, proba_test)\n",
    "    except ValueError: auroc = np.nan\n",
    "    rr_col_test = realized_return_column(ood)\n",
    "    tm = trading_metrics(y_test, yhat_test, ood[rr_col_test].to_numpy() if rr_col_test else None)\n",
    "\n",
    "    return {\n",
    "        \"alpha\": alpha, \"K\": K,\n",
    "        # CV\n",
    "        \"CV_Accuracy\": cv_acc, \"CV_Precision\": cv_prec, \"CV_Recall\": cv_rec, \"CV_F1\": cv_f1,\n",
    "        \"CV_MCC\": cv_mcc, \"CV_AUROC\": cv_auroc, \"CV_WinRate\": cv_wr,\n",
    "        \"CV_ProfitFactor\": cv_pf, \"CV_Sharpe_252\": cv_sharpe,\n",
    "        # OOD\n",
    "        \"OOD_Accuracy\": acc, \"OOD_Precision\": prec, \"OOD_Recall\": rec, \"OOD_F1\": f1,\n",
    "        \"OOD_MCC\": mcc, \"OOD_AUROC\": auroc,\n",
    "        \"OOD_WinRate\": tm[\"win_rate\"], \"OOD_ProfitFactor\": tm[\"profit_factor\"], \"OOD_Sharpe_252\": tm[\"sharpe_252\"]\n",
    "    }\n",
    "\n",
    "# ---- Run sweep ----\n",
    "results = []\n",
    "for a in ALPHAS:\n",
    "    for k in KS:\n",
    "        print(f\"\\n>>> Running Macro-Ret sweep: alpha={a}, K={k}\")\n",
    "        res = run_macroret(alpha=a, K=k)\n",
    "        results.append(res)\n",
    "\n",
    "sweep_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Sweep summary (sorted by OOD Sharpe) ===\")\n",
    "display(sweep_df.sort_values(\"OOD_Sharpe_252\", ascending=False))\n",
    "\n",
    "print(\"\\nTop-3 by OOD Profit Factor:\")\n",
    "display(sweep_df.sort_values(\"OOD_ProfitFactor\", ascending=False).head(3)[\n",
    "    [\"alpha\",\"K\",\"OOD_ProfitFactor\",\"OOD_Sharpe_252\",\"OOD_WinRate\",\"OOD_AUROC\"]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c8751-4da1-4a38-bc2c-b5279dfdfa48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
